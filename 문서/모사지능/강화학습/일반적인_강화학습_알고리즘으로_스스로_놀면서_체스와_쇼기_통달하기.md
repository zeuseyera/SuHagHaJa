
출처:
  - 논문 "Mastering Chess and Shogi by Self-Play with a
General Reinforcement Learning Algorithm(arXiv:1712.01815v)"

# 일반적인 강화학습 알고리즘으로 스스로 놀면서 체스와 쇼기 통달하기

> David Silver<sup>1*</sup>, Thomas Hubert<sup>1*</sup>, Julian Schrittwieser<sup>1*</sup>,  
> Ioannis Antonoglou<sup>1</sup>, Matthew Lai<sup>1</sup>, Arthur Guez<sup>1</sup>, Marc Lanctot<sup>1</sup>,  
> Laurent Sifre<sup>1</sup>, Dharshan Kumaran<sup>1</sup>, Thore Graepel<sup>1</sup>,  
> Timothy Lillicrap<sup>1</sup>, Karen Simonyan<sup>1</sup>, Demis Hassabis<sup>1</sup>
>
> <sup>1</sup> : 딥마인드, 6 판크라스 사거리, 런던 N1C 4AG.  
> <sup>*</sup> : 이 저자들은 이 작업에 동등하게 기여함.  

  ##### 요약

> 서양장기(체스)놀이는 인공지능 역사에서 가장 널리 연구된 영역이다. 강력한 프로그램은, 정교한 검색, 특정차원 적응, 그리고 수십년 동한 사람의 수작업에 의해 정련된 기술결합을 기반으로 한다. 이와 대조적으로, 알파고 제로 프로그램은 바둑놀이에서 사람을 초월하는 성능을 최근에 달성했다, 스스로놀기 놀이로부터 rasa로 정리(tabular)한 기록을 강화학습으로. 이 논문에서, 우리는 알파제로 알고리즘 하나로 접근하여 rasa를 기록, 많은 도전영역에서 사람을 초월하는 성능을 달성할수 있도록 일반화 했다. 무작정 놀기를 시작, 그리고 놀이규칙을 제외한 주어진 영역지식 없이, 알파제로는 서양장기와 일본장기 뿐만아니라 바둑놀이를 아주 잘 하여 사람을 초월하는 수준을 24시간 이내에 달성했다, 그리고 각각의 경우에서 세계챔피언 프로그램을 확실히 패배시켰다.

 체스의 컴퓨터 학습은 컴퓨터과학 만큼 오래되었다. 베비지, 튜링, 섀논, 그리고 본 뉴먼은 하드웨어, 알고리즘 그리고 서양장기(체스)놀이 놀기와 분석하기 위한 이론을 고안했다. 서양장기는 긴공지능 연구자 세대에게 큰 도전과제가 되었다, 사람을 초월하는 수준(9, 13)의 서양장기 프로그램은 고성능 컴퓨터에서 절정에 도달했다. 하지만, 이러한 시스템은 그러한 영역에 고도로 맞춰져 있다, 그리고 사람의 상당한 노력 없이는 다른 문제로 일반화할수 없다.

 인공지능의 오랜 야망의 첫번째 원칙은 스스로 배울수 있는 프로그램을 만드는 것이다(26). 최근에, 알파고 제로 알고리즘은 바둑놀이에서 사람을 초월하는 성능을 달성했다, 깊은 나선 신경망을(22, 28) 사용하여 바둑 지식을 표현함으로써, 스스로놀기 놀이로부터 강화학습으로 혼자서 벼림된(29). 이 논문에서, 우리는 비슷한 것을 적용한다 하지만 완전히 일반적인 알고리즘이다, 우리는 알파제로(AlphaZero)라고 부른다, 서양장기와 일본장기 뿐만아니라 바둑에서, 놀이규칙을 제외한 모든 추가적인 영역지식 없이, 일반목적 강화학습 알고리즘이 달성할 수 있음을 보여준다, rasa를 기록, 많은 도전영역에서 사람을 초월하는 성능을 달성.

 인공지능에 대한 지표는 1997년에 딥불루가 사람 세계챔피언을 패배시켰을때 달성되었다(9). 컴퓨터 서양장기 프로그램은 이후 20년 동한 꾸준히 사람수준을 넘어서 끊임없이 진행했다. 이러한 프로그램은 대가인 사람에 의한 수작업 특징을 사용하여 지위를 평가한다 그리고
